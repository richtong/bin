{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Rich's Fine Binary Utilities","text":"<p>These are (mainly by @richtong) convenience programs for use in installing and managing the dev environment. They are mainly experimental and are called from here. There are a few which are used and these are connected to local-bin. See local-bin/README.md for how to do that</p> <p>Most of time if you need to install something just try grepping</p>"},{"location":"dev/","title":"Developing","text":"<p>The rest of the programs are various scripts that are helpers after you create things. Rich is constantly adding to them. They use a common <code>include.sh</code> which loads libraries and finds WS_DIR.</p> <p>Since these are mainly experimental the vast majority a simple shell scripts. The ones that need it are rewritten as python such as the docker files that @sam did.</p> <p>These scripts have a couple of nice common features:</p> <ul> <li>They single step with -d flag. This flag is exported with DEBUGGING so you   just say -d once and all scripts called honor it.</li> <li>The same with the -v verbose flag.</li> <li>Libraries for these are kept in ../lib and are common shell functions. For   instance the debug behavior is in ../lib/lib-debug.sh</li> <li>They find the current WS_DIR automatically. They look up from their execution   directory for ws and if they can't find it, they look down from your HOME.</li> </ul> <p>Works most of time. If it doesn't, use export WS_DIR ahead of the script call. Or use wbash or wrun</p>"},{"location":"dev/#agent-scripts-vs-dev-scripts","title":"Agent scripts vs dev scripts","text":"<p>Some of these scripts are for use by agents. They are different mainly because agents for local build do not have sudo rights.</p>"},{"location":"dev/#helper-role-of-etc-and-lib","title":"Helper role of ../etc and ../lib","text":"<p>The ../etc files are text configuration files:</p> <p>users.txt: This is a list of user names, uid and gids groups.txt: common groups used on common machines hostnames.txt: hostnames already in use wordlist.txt: a list of hostnames not allocated for use by new machines</p>"},{"location":"files/","title":"Files","text":"<p>This is not a complete list as it is manually generated. The next step is to use a shell extract to get it.</p> <ul> <li>create-keys.sh - Creates ssh keys securely using latest on disk encryption</li> <li>docker-machine-create.sh - So you can have a docker machine swarm</li> <li>git-reset.sh - When you just want everything reset to master</li> <li>install-1password.sh - Installs Linux 1-password</li> <li>install-accounts.sh - Used by prebuild, this populates your local machine with</li> <li>all user accounts</li> <li>install-agent.sh - Run by a local agent to create crontab etc</li> <li>install-agents.sh - Creates all agent currently test, build and deploy</li> <li>install-apache.sh - Installs apache</li> <li>install-aws-config.sh - Installs your personal config of aws from your secret</li> <li>keys</li> <li>install-aws.sh - Installs aws command line</li> <li>install-caffe.sh - Not complete, but this installs caffe</li> <li>install-crontab.sh - Installs entries into crontab used by agents</li> <li>install-dwa182.sh - For the D-link Wifi USB adapter (AC1200!)</li> <li>install-flocker.sh - not complete, this is docker for data volumes</li> <li>install-hostname.sh - Gives you a new hostname from wordlist.txt</li> <li>install-lfs.sh - Installs lfs for you</li> <li>install-mail.sh - Used by agents, verifies that ssmtp is installed</li> <li>install-modular-boost.sh - Not used but testing for modular boost standalone</li> <li>install-neon.sh - Not complete for Neon machine learning</li> <li>install-nvidia.sh - Installs nvidia proprietary drivers</li> <li>install-pia.sh - Installs Private Internet access VPN</li> <li>install-ruby.sh - Not sued, installs ruby</li> <li>install-spotify.sh - Installs spotify for Linux, not debugged</li> <li>install-sshd.py - Installs the ssh daemon so you can ssh into your machine</li> <li>install-ssmtp.sh - Installs a simple mail transport send through ops@surround.io</li> <li>install-sublime.sh - Installs sublime, not debugged</li> <li>install-travis-env.sh - Installs the travis routines for 12.04, deprecated,</li> <li>install-travis.sh - Installs travis, not debugged</li> <li>install-vim.py - deprecated Vim lint checkers for sh, python, Javascript</li> <li>install-vim.sh - installs vim</li> <li>install-vmware-tools.sh - Checks for latest vmware tools</li> <li>install-vpn.sh - Installs a vpn file</li> <li>make-bin.sh - Converts one of these files into a general use with src/bin</li> <li>make-password.sh - Creates a secure password</li> <li>remove-accounts.sh - Cleans up a machine removing all create by install-users.sh</li> <li>remove-agents.sh - Cleans up install-agents.sh</li> <li>remove-all.sh - Cleans everything that accounts and agents does</li> <li>remove-crontab.sh - Removes all crontab entries</li> <li>remove-prebuild.sh - Removes all the files create</li> <li>start-vpn.sh - starts a vpn to surround.io</li> <li>system-run.sh - used by agents, runs wscons and starts alpha 2</li> <li>system-test.sh - Not debugged yet, but runs system wide tests for alpha 2</li> <li>verify-docker.sh - Ensures we have the rights to run docker</li> </ul>"},{"location":"install/","title":"Installation","text":"<p>Installation and configuration depend on a few key variables like WS_DIR and having a bootstrap that depends on the environment variables.</p>"},{"location":"install/#ws_dir-and-directory-layout","title":"WS_DIR and directory layout","text":"<p>The key shell variable is WS_DIR which is set by include.sh this does a search for the directories the parents of a directory close to the script with a directory <code>git</code> in it. So if there are multiple workspace directories you can end up with errors, it will search alphabetically, so naming is important, by convention, put your primary workspace in <code>~/ws</code> and then if you have other projects add a letter, so ~/ws is always your first parent with a <code>~/ws/git</code> in it.</p> <p>The same applies inside your workspace, the <code>lib_source</code> function loads in shell libraries, it searches up and down git looking for a <code>lib</code> directory. If you have for instance cloned ~/ws/git/lib but also have a ~/ws/git/src/lib, it will pick the first as the library, so when you are working these submodules, use then in the ~/ws/src.</p> <p>Also if you have more than one ~/ws, be aware that the way search works, you ~/wsr/src/lib for instance is \"shadowed\" and will not be seen as a library.</p>"},{"location":"install/#preinstall-on-naked-or-bare-metal-installation","title":"Preinstall on naked or bare metal installation","text":"<p>For a non-networked machine, To do a bare metal build, create-preinstall.sh which will give you enough of this system to put onto a USB key and then bootstrap from there.</p> <p>Normally you should just clone an entire src repo which will have a bin and lib submodules. The preinstall will take a Mac convert it with enough git and bash to run.</p> <p>To have everything ready, it assumes you have a Veracrypt installation with your passwords on it in your username.vc which lives on your Google Drive. It will link your keys from there into ~/.ssh which is nice</p> <p>It also assumes you have a src/user/your name/dotfiles directory and will link your profile and other configurations there.</p> <p>If you have a network, then you should do:</p> <pre><code># install brew with the one line ruby code that is on their site\ngit clone --recurse https://github.com/richtong/src\ncd src/bin\n./preinstall.sh -v\n./install.sh -v\n</code></pre>"},{"location":"install/#installation-details","title":"Installation Details","text":"<p>This assumes that there is a next door directory <code>../lib</code> which has library functions. Normally, this is a submodule based on @richtong's library.</p> <p>You normally put both into a <code>rt/{bin, lib}</code> directories in your project. Or if you are not going to be using any other bins, then put directly into /bin or /lib of the repo</p> <p>If you are contributing code then run <code>make pre-commit</code> and use shellcheck to make sure you are writing good shell scripts. It is also a good idea to add this directory to your path in <code>.bash_profile</code></p> <p>So the installation works like:</p> <pre><code>cd ~/ws/git/src  # or where your repo is\ngit submodule add git@github.com:richtong/bin\ncd bin\nmake repo-init\n</code></pre>"},{"location":"install/#global-variables","title":"Global variables","text":"<p>These are kept in [../lib/include.sh] and you should change ORG_NAME to reflect where you have forked things</p>"},{"location":"install/#aws-installsh-deprecated","title":"AWS Install.sh (deprecated)","text":"<p>This is @rich's poor attempt to automate things. But if you just want to do a basic installation, here are the steps:</p> <ol> <li>Get your AWS accounts and add your public keys to the iam console</li> <li>Get a new machine and create and login, you want to create an administrative    account to do this, follow the AWS standard and use the account name    <code>ubuntu</code> from there you want to get the iam key service started</li> </ol> <pre><code>curl -s http://download.xevo-dev.net/bootstrap/install-iam-key-daemon.sh \\\n   | bash -s\n</code></pre> <ol> <li>Now you need to hand edit your <code>/etc/opt/xevo/iam-key.conf.yml</code> at a minimum    add yourself as a user at the maximum uncomment docker, sudo, sudonopass</li> <li>Now logout and ssh in as your actual user identity. Leave the ubuntu on as a    backdoor in case you need to configure</li> </ol> <pre><code>sudo apt-get install git\nmkdir -p ws/git\ncd ws/git\ngit clone https://github.com/surround-io/src\ncd src/infra/bin\n</code></pre> <ol> <li>Now you can run install to make sure the defaults are OK run <code>install.sh -h</code>    and you can see how it will configure override with the appropriate flag. It    tries to guess your user name and your docker name but often guesses wrong    particularly with docker.</li> </ol> <pre><code>~/ws/git/src/infra/bin/install.sh -r _your dockeR name_\n</code></pre> <ol> <li>Note that install.sh works on Debian 9, Ubuntu 14.04, ubuntu 16.0. It also    runs inside VMware fusion</li> </ol>"},{"location":"install/#configuring-your-mac","title":"Configuring your Mac","text":"<p>Note that <code>install.sh</code> also works to configure your Mac as a development machine, so here are the steps:</p> <ol> <li>Git clone on your mac to <code>mkdir -p ws/git; cd ws/git; git clone surround-</code></li> <li>Run <code>install.sh</code></li> </ol>"},{"location":"setup/","title":"Security","text":"<p>This is the hardest part of getting things right. Most of this is not necessary if you use 1Password and enable their ssh-agent.</p>"},{"location":"setup/#ssh-key-setup","title":"SSH key setup","text":"<ol> <li>First, create a <code>public-keys/ssh/$USER/</code> directory and put into it    your public and encrypted keys to access github.</li> <li> <p>When you are making your keys, you probably want to use the new features in    OpenSSH 6.5 and in particular use the <code>-o</code> flag which bcrypt rather than the weak MD5 encryption that is the default. Also set the rounds up from the default 16 to something more like <code>-a 300</code> which should take a few seconds on a fast computer and make it hard to brute force your ssh keys. The script prebuild-keys.sh does this for you.</p> </li> <li> <p>To keep track of your keys, @rich's scripts use this syntax for keys, user    email-web url for the site you want to login to.type of key. We use this    instead of the generic id_rsa you see in examples so you can repudiate services    individually and so that one key loss doesn't mean access to everything you    have.</p> </li> <li>The unencrypted AWS credentials are kept in the .Private and Private.dmg (for    Linux and Mac respectively</li> </ol>"},{"location":"setup/#continue-the-installation-if-this-is-a-general-surround-machines","title":"Continue the installation if this is a general surround machines","text":"<p>When prebuild is complete you should be able to configure the system, so here are the rest of the steps if this is not a personal machined</p> <ol> <li>Once install is complete you have your local environment. Now run    <code>src/infra/bin/install-users.sh</code> and this will create all the other    developers and agents for surround.</li> <li>At this point any developer should be able to ssh into the machine and agents    are ready to run.</li> </ol>"},{"location":"setup/#configure-a-deployment-machine-or-a-testing-machine","title":"Configure a deployment machine or a testing machine","text":"<p>With this done, you can now decide if you also want the various automated systems to run as well here. What they are:</p>"},{"location":"setup/#installing-agents","title":"Installing agents","text":"<p>This agent runs in its own account and is designed to run 'wscons pre' continuously and report back via email as to what has happened.</p> <ol> <li>Copy the ssh keys needed for agents with ~/prebuild/ssh/{build,test,deploy}    run from your context.</li> <li>Run prebuild.sh with the -c to create a deployment machine or the -t for a    testing machine running unit and system test.</li> <li>If you decide to do later, then you need to run    personal/rich/bin/install-accounts.sh to get all the accounts</li> <li>Then for each separate agent, go to their context and run    personal/rich/bin/install-agents.sh</li> </ol>"},{"location":"setup/#function-so-each-agent","title":"Function so each agent","text":"<p>Here are the functions:</p> <ul> <li>build. This just runs Scons pre continuously as a clean build.</li> <li>test. This runs the automated system test. Configuring cameras and running   against a test to make sure that the web server and the camera feeds work. It   then takes them down</li> <li>deploy. This runs the app-host and web server so things are ready for service</li> </ul>"},{"location":"setup/#creating-a-file-server","title":"Creating a file server","text":"<p>First create a special admin account typically called 'surround' and then you will create the surround.io standard accounts and then install ZFS</p> <pre><code>mkdir -p ~/ws/git\ncd ~/ws/git\ngit clone https://github.com/surround-io/src\ncd ~/ws/src/infra/bin\n./install-accounts.sh\n</code></pre> <p>Now you want to see what you have</p>"},{"location":"setup/#using-the-raspberry-pi-as-a-dockerized-camera-system","title":"Using the Raspberry Pi as a dockerized camera system","text":"<p>This is @rich's side project. Here is what you need to do:</p> <ol> <li>Get a set of Raspberry Pi's with their cameras installed. We have lots so    just ask Rich for a set we have literally a hundred of them.</li> <li>Download the SD and then mount it, then config-hypriot.sh will customize the    /boot/config.txt so that it will overclock our model B and turn on the    cameras.</li> <li>Run install-hypriot.sh which will download the SD images, then put them onto    a SD for each pi. As of now, you have to name each Pi so that is a pain. Each    is distinct</li> <li>When this is up, then you can run hypriot-camera.sh to take photos. The    default is ~/ws/runtime/rpi</li> </ol>"},{"location":"special/","title":"Special","text":"<p>Here are some special things you can do to create a ZFS server or a Raspberry Pi setup.</p>"},{"location":"special/#creating-a-file-server","title":"Creating a file server","text":"<p>First create a special admin account typically called 'surround' and then you will create the surround.io standard accounts and then install ZFS</p> <pre><code>mkdir -p ~/ws/git\ncd ~/ws/git\ngit clone https://github.com/surround-io/src\ncd ~/ws/src/infra/bin\n./install-accounts.sh\n</code></pre> <p>Now you want to see what you have</p>"},{"location":"special/#using-the-raspberry-pi-as-a-dockerized-camera-system","title":"Using the Raspberry Pi as a dockerized camera system","text":"<p>This is @rich's side project. Here is what you need to do:</p> <ol> <li>Get a set of Raspberry Pi's with their cameras installed. We have lots so    just ask Rich for a set we have literally a hundred of them.</li> <li>Download the SD and then mount it, then config-hypriot.sh will customize the    /boot/config.txt so that it will overclock our model B and turn on the    cameras.</li> <li>Run install-hypriot.sh which will download the SD images, then put them onto    a SD for each pi. As of now, you have to name each Pi so that is a pain. Each    is distinct</li> <li>When this is up, then you can run hypriot-camera.sh to take photos. The    default is ~/ws/runtime/rpi</li> </ol>"},{"location":"test/","title":"Testing","text":"<p>This uses a pre-commit pipeline that checks for markdown, shellscript and other errors. It also checks for properly formatted git commit rules. You should use an editor like vim with a plugin like ALE to do this syntax checking. Currently we are using markdownlint-cli, shellcheck, mypy and black for markdown, shell scripts and python. There could be more later.</p> <p>Also this repository uses the Angular git commit conventions:</p> <ol> <li>The one line header should be type(scope): summary without period or    capitals. As an example <code>fix(install-docker.sh): shellchecked</code> means that    there was a non-breaking fix for this file and then says shellcheck was    uses. The valid types are \"fix, feat, perf, refactor, test, docs, ci, build\"    which mean a bug fix, new feature, performance improvement, refactoring so    neither a fix nor a feature, test to add or fix testing, ci for CI config    changes like github actions and build for build system things like npm.</li> <li>There is required message body that explains why the change is made or what    behavior changes, should be written in imperitive present so \"fix\" not    \"fixed\" or \"fixes\"</li> <li>The footer may include a GitHub issue with Fixes #23 to fix issue 23 or if    it is break changing then BREAKING CHANGE or DEPRECATED if something is    going away and then Closes #12 to close Pull Request #12</li> </ol>"}]}